{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!pip install pandas==1.3.1\n",
    "\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# %matplotlib inline\n",
    "import tensorflow\n",
    "from google.colab import drive\n",
    "from matplotlib import rcParams\n",
    "from pandas.tseries.offsets import DateOffset\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TensorBoard\n",
    "from tensorflow.keras.layers import Bidirectional\n",
    "from tensorflow.keras.layers import Conv1D\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.losses import Huber\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.callbacks import History\n",
    "\n",
    "rcParams.update({'figure.autolayout': True})\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "tensorflow.keras.backend.clear_session()\n",
    "\n",
    "# Configuration\n",
    "EPOCHS = 1\n",
    "DROPOUT = 0.1\n",
    "BATCH_SIZE = 128\n",
    "LOOK_BACK = 100\n",
    "UNITS = LOOK_BACK * 1\n",
    "VALIDATION_SPLIT = .01\n",
    "PREDICTION_RANGE = LOOK_BACK\n",
    "DYNAMIC_RETRAIN = False\n",
    "USE_SAVED_MODELS = False\n",
    "SAVE_MODELS = False\n",
    "\n",
    "\n",
    "def summary(for_model: Model) -> str:\n",
    "    summary_data = []\n",
    "    for_model.summary(print_fn=lambda line: summary_data.append(line))\n",
    "    return '\\n'.join(summary_data)\n",
    "\n",
    "\n",
    "def create_model_callbacks(es_patience: int = 40, lr_patience: int = 30) -> []:\n",
    "    es = EarlyStopping(monitor='loss', min_delta=1e-10, patience=es_patience, verbose=1)\n",
    "    rlr = ReduceLROnPlateau(monitor='loss', factor=0.2, patience=lr_patience, verbose=1)\n",
    "    mcp = ModelCheckpoint(filepath='weights.h5', monitor='loss', verbose=1, save_best_only=True,\n",
    "                          save_weights_only=True)\n",
    "\n",
    "    tb = TensorBoard('logs')\n",
    "    return [es, rlr, mcp, tb]\n",
    "\n",
    "\n",
    "def moving_average(array: [], w: int) -> []:\n",
    "    return np.concatenate((np.full(w - 1, array[w]), np.convolve(array, np.ones(w), 'valid') / w))\n",
    "\n",
    "\n",
    "def df_info(name: str, data):\n",
    "    print(f'\\n{name}.shape: {data.shape}')\n",
    "    print(f'{name}.describe(): {data.describe()}')\n",
    "    print(f'{name}.head(): {data.head()}')\n",
    "    print(f'{name}.tail(): {data.tail()}')\n",
    "    print('\\n')\n",
    "\n",
    "\n",
    "def build_model(n_output: int) -> Model:\n",
    "    new_model = Sequential()\n",
    "    new_model.add(Conv1D(filters=LOOK_BACK, kernel_size=5,\n",
    "                         strides=1, padding=\"causal\",\n",
    "                         activation=\"relu\",\n",
    "                         input_shape=(x.shape[1], N_FEATURES)))\n",
    "    # new_model.add(\n",
    "    #     Bidirectional(LSTM(units=UNITS, activation='relu', input_shape=(x.shape[1], N_FEATURES), return_sequences=True)))\n",
    "    # new_model.add(\n",
    "    #     Bidirectional(LSTM(units=UNITS, activation='relu', input_shape=(x.shape[1], N_FEATURES))))\n",
    "    # new_model.add(Dropout(DROPOUT))\n",
    "    # new_model.add(LSTM(units=UNITS, return_sequences=True, input_shape=(x.shape[1], N_FEATURES)))\n",
    "    new_model.add(Bidirectional(LSTM(units=UNITS, activation='relu', return_sequences=True)))\n",
    "    # new_model.add(Dropout(DROPOUT))\n",
    "    new_model.add(Bidirectional(LSTM(units=UNITS, activation='tanh', return_sequences=True)))\n",
    "    # new_model.add(Dropout(DROPOUT))\n",
    "    # new_model.add(Bidirectional(LSTM(units=UNITS, activation='relu', return_sequences=True)))\n",
    "    # new_model.add(Dropout(DROPOUT))\n",
    "    new_model.add(Bidirectional(LSTM(units=UNITS, activation='linear')))\n",
    "    # new_model.add(Dropout(DROPOUT))\n",
    "    # new_model.add(LSTM(units=UNITS))\n",
    "    new_model.add(Dense(units=n_output))\n",
    "    # new_model.add(Dense(units=N_FEATURES))\n",
    "\n",
    "    new_model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    # optimizer = SGD(lr=1e-1, momentum=0.9)\n",
    "    # new_model.compile(loss=Huber(),\n",
    "    #               optimizer=optimizer,\n",
    "    #               metrics=[\"mae\"])\n",
    "    return new_model\n",
    "\n",
    "\n",
    "def fit_model(new_x: [], new_y: [], new_model: Model, epochs: int = EPOCHS, split: float = VALIDATION_SPLIT,\n",
    "              es_patience: int = 40, lr_patience: int = 30) -> [Model, History]:\n",
    "    new_model.fit(new_x, new_y, epochs=epochs, batch_size=BATCH_SIZE,\n",
    "                  callbacks=create_model_callbacks(es_patience, lr_patience),\n",
    "                  validation_split=split\n",
    "                  )\n",
    "    new_model.load_weights(filepath=\"weights.h5\")\n",
    "    return [new_model, new_model.history]\n",
    "\n",
    "\n",
    "def get_updated_x(x_last: [], last_prediction: []) -> []:\n",
    "    # print(f'x_last input values: {x_last[-1]}')\n",
    "\n",
    "    x_last = np.append(x_last[1:], last_prediction)\n",
    "    x_last = x_last.reshape(LOOK_BACK, N_FEATURES)\n",
    "    # print(f'x_last new: {X_last}')\n",
    "    # print(f'x_last input values new: {x_last[-1]}')\n",
    "\n",
    "    return np.expand_dims(x_last, axis=0)\n",
    "\n",
    "\n",
    "def get_stats() -> str:\n",
    "    return f'loss: {history.history.get(\"loss\")[-1]} \\n ' \\\n",
    "           f'val_loss: {history_val.history.get(\"val_loss\")[-1]} \\n ' \\\n",
    "           f'EPOCHS: {EPOCHS} DYNAMIC_RETRAIN: {DYNAMIC_RETRAIN} \\n ' \\\n",
    "           f'UNITS: {UNITS} \\n ' \\\n",
    "           f'BATCH_SIZE: {BATCH_SIZE} \\n ' \\\n",
    "           f'LOOK_BACK: {LOOK_BACK} \\n ' \\\n",
    "           f'VALIDATION_SPLIT: {VALIDATION_SPLIT} \\n ' \\\n",
    "           f'DROPOUT: {DROPOUT} \\n ' \\\n",
    "           f'N_FEATURES: {N_FEATURES} \\n ' \\\n",
    "           f'PREDICTION_RANGE: {PREDICTION_RANGE} '\n",
    "\n",
    "\n",
    "def predict(model: Model, x: [], x_test: [], y:[], prediction_range: int = PREDICTION_RANGE) -> []:\n",
    "    y_predict = model.predict(x_test)\n",
    "    for prediction_steps in range(prediction_range):\n",
    "        x_predict = get_updated_x(x[-1], y_predict[-1])\n",
    "        y_predict_new = model.predict(x_predict)\n",
    "\n",
    "        # break at extreme values\n",
    "        if abs(y_predict_new[0, 1]) > 2:\n",
    "            break\n",
    "\n",
    "        print(y_predict_new[0, 1])\n",
    "        x = np.append(x, x_predict, axis=0)\n",
    "\n",
    "        y_predict = np.append(y_predict, y_predict_new, axis=0)\n",
    "        # y_predict = np.append(y_predict, [ct}')\n",
    "\n",
    "        # dynamic retrain\n",
    "        if DYNAMIC_RETRAIN:\n",
    "            y = np.append(y, y_predict_new, axis=0)\n",
    "            model, history = fit_model(x, y, model, epochs=5, es_patience=4, lr_patience=3)\n",
    "            # y = np.append(y, y_predict_new[, model, epochs=5, es_patience=4, lr_patience=3)\n",
    "\n",
    "    return y_predict\n",
    "\n",
    "\n",
    "drive.mount('/drive')\n",
    "\n",
    "# Download data\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:89.0) Gecko/20100101 Firefox/89.0\"}\n",
    "df = pd.read_csv(\"https://www.coingecko.com/price_charts/export/1/usd.csv\", parse_dates=['snapped_at'],\n",
    "                 storage_options=headers)\n",
    "df.to_csv('/Colab Notebooks/cryptofuture/data/btc_price.csv')\n",
    "df = df.fillna(df.mean())\n",
    "dates = df.iloc[:, [0]].values\n",
    "\n",
    "df_info('df', df)\n",
    "\n",
    "# https://docs.coinmetrics.io/info/metrics\n",
    "df_coin = pd.read_csv('https://coinmetrics.io/newdata/btc.csv', parse_dates=['date'],\n",
    "                      storage_options=headers)\n",
    "df_coin.to_csv('/Colab Notebooks/cryptofuture/data/btc_metrics.csv')\n",
    "df_coin = pd.read_csv('data/btc_metrics.csv', parse_dates=['date'])\n",
    "df_coin = df_coin.drop(columns=['date'])\n",
    "df_coin = df_coin.fillna(df_coin.mean())\n",
    "df_coin = df_coin.drop(df_coin.index[:1577])\n",
    "df_coin.rename(columns={'Unnamed: 0': 'index'}, inplace=True)\n",
    "df_coin['index'] = df_coin['index'] - 1577\n",
    "df_coin = df_coin.set_index('index')\n",
    "\n",
    "df_info('df_coin', df_coin)\n",
    "\n",
    "# Join dataframes\n",
    "df = df.join(df_coin)\n",
    "\n",
    "# Put the date column in the index.\n",
    "df = df.set_index(\"snapped_at\")\n",
    "\n",
    "# add moving averages\n",
    "open_values = df['price'].to_numpy()\n",
    "print(f'open_values: {open_values}')\n",
    "\n",
    "for m in range(10, 210, 10):\n",
    "    ma = moving_average(open_values, m).tolist()\n",
    "    print(f'ma_{m}: {ma}')\n",
    "    df[f'ma_{m}'] = ma\n",
    "\n",
    "# Fill nan values\n",
    "df = df.fillna(df.mean())\n",
    "\n",
    "df_info('df', df)\n",
    "\n",
    "input_feature = df.iloc[:, :].values\n",
    "N_FEATURES = len(input_feature[0])\n",
    "input_data = input_feature.copy()\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "input_data[:, 0:N_FEATURES] = scaler.fit_transform(input_feature[:, :])\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "for i in range(len(df) - LOOK_BACK - 1):\n",
    "    t = []\n",
    "    for j in range(0, LOOK_BACK):\n",
    "        t.append(input_data[[(i + j)], :])\n",
    "    x.append(t)\n",
    "    y.append(input_data[i + LOOK_BACK, :])\n",
    "\n",
    "x, y = np.array(x), np.array(y)\n",
    "\n",
    "x_test = x[-2 * LOOK_BACK:]\n",
    "x = x.reshape(x.shape[0], LOOK_BACK, N_FEATURES)\n",
    "x_test = x_test.reshape(x_test.shape[0], LOOK_BACK, N_FEATURES)\n",
    "print(f'x.shape: {x.shape}')\n",
    "print(f'x_test.shape: {x_test.shape}')\n",
    "\n",
    "if USE_SAVED_MODELS:\n",
    "    model_val = tensorflow.keras.models.load_model(\"models/model_val\")\n",
    "    model = tensorflow.keras.models.load_model(\"models/model\")\n",
    "else:\n",
    "    model_val = build_model(N_FEATURES)\n",
    "    model = build_model(N_FEATURES)\n",
    "\n",
    "model_val, history_val = fit_model(x, y, model_val)\n",
    "tensorflow.keras.backend.clear_session()\n",
    "model, history = fit_model(x, y, model, split=0)\n",
    "\n",
    "if SAVE_MODELS:\n",
    "    model.save('models/model')\n",
    "\n",
    "y_predict_val = predict(model_val, x, x_test, y, prediction_range=0)\n",
    "y_predict = predict(model, x, x_test, y)\n",
    "\n",
    "# Inverse scale value\n",
    "y_predict = scaler.inverse_transform(y_predict)\n",
    "y_predict = y_predict[:, 0]\n",
    "\n",
    "y_predict_val = scaler.inverse_transform(y_predict_val)\n",
    "y_predict_val = y_predict_val[:, 0]\n",
    "\n",
    "plot_dates = dates[-2 * LOOK_BACK:]\n",
    "\n",
    "add_dates = [dates[-1] + DateOffset(days=x) for x in range(0, PREDICTION_RANGE + 1)]\n",
    "\n",
    "predict_dates = np.concatenate([plot_dates[:-1], add_dates])\n",
    "\n",
    "# Plot graph\n",
    "plt.figure(figsize=(20, 8))\n",
    "plt.plot(dates[-2 * LOOK_BACK:, 0], input_feature[-2 * LOOK_BACK:, 0], color='green', label='Actual')\n",
    "plt.plot(predict_dates[:-PREDICTION_RANGE], y_predict_val, color='orange', label='Validation')\n",
    "plt.plot(predict_dates, y_predict, color='red', label='Prediction')\n",
    "plt.axvline(dates[-1, 0], color='blue', label='Prediction split')\n",
    "if VALIDATION_SPLIT > 0:\n",
    "    plt.axvline(dates[int(-1 - VALIDATION_SPLIT * len(x)), 0], color='purple', label='Validation split')\n",
    "plt.title(f'BTC Price Prediction (NFA! No Warranties!) - USE_SAVED_MODELS: {USE_SAVED_MODELS}')\n",
    "plt.legend(loc='best', fontsize='xx-large')\n",
    "plt.xlabel(\"Time (latest-> oldest)\")\n",
    "plt.ylabel(\"Opening Price\")\n",
    "plt.figtext(0.7, 0.05, get_stats(), ha=\"center\", fontsize=10, bbox={\"facecolor\": \"orange\", \"alpha\": 0.5, \"pad\": 5})\n",
    "plt.annotate(summary(model), (0, 0), (0, -40), xycoords='axes fraction', textcoords='offset points', va='top')\n",
    "plt.annotate(model.optimizer, (0, 0), (600, -40), xycoords='axes fraction', textcoords='offset points', va='top')\n",
    "\n",
    "plt.savefig(\n",
    "    f'plots/BTC_price_{pd.to_datetime(df.index[-1]).date()}_{EPOCHS}_{BATCH_SIZE}_{LOOK_BACK}_{history.history.get(\"loss\")[-1]}.png')\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('venv': venv)"
  },
  "interpreter": {
   "hash": "44bf7ddb6e0da5bf7c39d525bd904638f3d81acc9e7197fb4c79fe26f21e6f8c"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}